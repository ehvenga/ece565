{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65f745db-050c-48b3-b54d-175f819b9fcc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Logistic Regression\n",
    "\n",
    "### Exam 1b\n",
    "\n",
    "1. Read train.csv and test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e6ece73-7ca0-43a4-b6a1-cf59570a0efa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape = (3000, 10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "print(f'data shape = {train_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32058ac-0703-4034-9753-e3a828c7686d",
   "metadata": {},
   "source": [
    "2. Split into 70% train, 20% validation and 10% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbee4bc4-d7ac-430d-9dbc-02d24fdeb3eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape = (2100, 10)\n",
      "validation data shape = (600, 10)\n",
      "test data shape = (300, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into 70% train and 30% temporary\n",
    "train_data, temp_data = train_test_split(train_df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the temporary set into 20% validation and 10% test\n",
    "validation_data, test_data = train_test_split(temp_data, test_size=1/3, random_state=42)\n",
    "\n",
    "print(f'training data shape = {train_data.shape}')\n",
    "print(f'validation data shape = {validation_data.shape}')\n",
    "print(f'test data shape = {test_data.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8c39da-4a70-4825-9959-2ee5133d3c8c",
   "metadata": {},
   "source": [
    "3. Pre-setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83c9db14-f876-4986-a89d-030574527a16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize weights randomly for 9 features, the bias term will be included as w1\n",
    "W = np.random.rand(10)\n",
    "\n",
    "# Set hyperparameters\n",
    "alpha = 0.01  # Learning rate\n",
    "epsilon = 0.00001  # Convergence criterion\n",
    "epochs = 10000  # Number of iterations over the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3c54423-86dd-4b34-b98f-1f0bd3377600",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (2100, 10)\n",
      "Shape of y: (2100,)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "features = train_data.iloc[:, :-1]  # all rows, all columns except the last one\n",
    "target = train_data.iloc[:, -1]  # all rows, just the last column\n",
    "\n",
    "# Number of samples\n",
    "M = features.shape[0]\n",
    "\n",
    "# Add a column of ones to the feature matrix to account for the bias term\n",
    "X = np.hstack((np.ones((M, 1)), features.values))\n",
    "\n",
    "# Target vector\n",
    "y = target.values\n",
    "\n",
    "# Verify the shapes of X and y\n",
    "print(\"Shape of X:\", X.shape)  # Should be (M, 10) including the bias term\n",
    "print(\"Shape of y:\", y.shape)  # Should be (M,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "303f009a-c86f-4ac5-8343-36a10d01f64f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2100,10) and (1,10) not aligned: 10 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m W, cost_history\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Perform gradient descent\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m W, cost_history \u001b[38;5;241m=\u001b[39m gradient_descent(X, y, W, alpha, epsilon, epochs)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Output the final weights and cost\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal weights:\u001b[39m\u001b[38;5;124m\"\u001b[39m, W)\n",
      "Cell \u001b[1;32mIn[5], line 19\u001b[0m, in \u001b[0;36mgradient_descent\u001b[1;34m(X, y, W, alpha, epsilon, epochs)\u001b[0m\n\u001b[0;32m     15\u001b[0m cost_history \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# Keep track of the cost every epoch for plotting/verification purposes\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# Step 1: Calculate the hypothesis h using matrix multiplication\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m     h \u001b[38;5;241m=\u001b[39m sigmoid(np\u001b[38;5;241m.\u001b[39mdot(X, W))\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# Step 2: Calculate the error\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     error \u001b[38;5;241m=\u001b[39m h \u001b[38;5;241m-\u001b[39m y\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (2100,10) and (1,10) not aligned: 10 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Sigmoid function definition\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Cost function definition for logistic regression\n",
    "def compute_cost(X, y, W):\n",
    "    m = y.shape[0]\n",
    "    h = sigmoid(np.dot(X, W))\n",
    "    cost = -(1/m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
    "    return cost\n",
    "\n",
    "# Gradient descent function definition\n",
    "def gradient_descent(X, y, W, alpha, epsilon, epochs):\n",
    "    m = y.shape[0]\n",
    "    cost_history = []  # Keep track of the cost every epoch for plotting/verification purposes\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Step 1: Calculate the hypothesis h using matrix multiplication\n",
    "        h = sigmoid(np.dot(X, W))\n",
    "        \n",
    "        # Step 2: Calculate the error\n",
    "        error = h - y\n",
    "        \n",
    "        # Step 3: Calculate the gradient using matrix multiplication\n",
    "        gradient = np.dot(X.T, error) / m\n",
    "        \n",
    "        # Step 4: Update the weights using matrix subtraction and scalar multiplication\n",
    "        W_old = W.copy()\n",
    "        W = W - alpha * gradient\n",
    "        \n",
    "        # Optional: Save the cost to the history for later\n",
    "        cost = compute_cost(X, y, W)\n",
    "        cost_history.append(cost)\n",
    "        \n",
    "        # Step 5: Check for convergence (if the change in cost function is less than epsilon)\n",
    "        if np.all(np.abs(W_old - W) < epsilon):\n",
    "            print(f'Convergence reached at epoch: {epoch}')\n",
    "            break\n",
    "    \n",
    "    return W, cost_history\n",
    "\n",
    "# Perform gradient descent\n",
    "W, cost_history = gradient_descent(X, y, W, alpha, epsilon, epochs)\n",
    "\n",
    "# Output the final weights and cost\n",
    "print(\"Final weights:\", W)\n",
    "print(\"Final cost:\", cost_history[-1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
