{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65f745db-050c-48b3-b54d-175f819b9fcc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Logistic Regression\n",
    "\n",
    "### Exam 1b\n",
    "\n",
    "1. Read train.csv and test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e6ece73-7ca0-43a4-b6a1-cf59570a0efa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape = (3000, 10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "print(f'data shape = {train_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32058ac-0703-4034-9753-e3a828c7686d",
   "metadata": {},
   "source": [
    "2. Split into 70% train, 20% validation and 10% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbee4bc4-d7ac-430d-9dbc-02d24fdeb3eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scikit_learn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscikit_learn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Split into 70% train and 30% temporary\u001b[39;00m\n\u001b[0;32m      3\u001b[0m train_data, temp_data \u001b[38;5;241m=\u001b[39m train_test_split(train_df, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scikit_learn'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split into 70% train and 30% temporary\n",
    "train_data, temp_data = train_test_split(train_df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the temporary set into 20% validation and 10% test\n",
    "validation_data, test_data = train_test_split(temp_data, test_size=1/3, random_state=42)\n",
    "\n",
    "print(f'training data shape = {train_data.shape}')\n",
    "print(f'validation data shape = {validation_data.shape}')\n",
    "print(f'test data shape = {test_data.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8c39da-4a70-4825-9959-2ee5133d3c8c",
   "metadata": {},
   "source": [
    "3. Pre-setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c9db14-f876-4986-a89d-030574527a16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize weights randomly for 9 features, the bias term will be included as w1\n",
    "W = np.random.rand(10)\n",
    "\n",
    "# Set hyperparameters\n",
    "alpha = 0.01  # Learning rate\n",
    "epsilon = 0.00001  # Convergence criterion\n",
    "epochs = 10000  # Number of iterations over the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c54423-86dd-4b34-b98f-1f0bd3377600",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "features = train_data.iloc[:, :-1]  # all rows, all columns except the last one\n",
    "target = train_data.iloc[:, -1]  # all rows, just the last column\n",
    "\n",
    "# Number of samples\n",
    "M = features.shape[0]\n",
    "\n",
    "# Add a column of ones to the feature matrix to account for the bias term\n",
    "X = np.hstack((np.ones((M, 1)), features.values))\n",
    "\n",
    "# Target vector\n",
    "y = target.values\n",
    "\n",
    "# Verify the shapes of X and y\n",
    "print(\"Shape of X:\", X.shape)  # Should be (M, 10) including the bias term\n",
    "print(\"Shape of y:\", y.shape)  # Should be (M,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303f009a-c86f-4ac5-8343-36a10d01f64f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sigmoid function definition\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Cost function definition for logistic regression\n",
    "def compute_cost(X, y, W):\n",
    "    m = y.shape[0]\n",
    "    h = sigmoid(np.dot(X, W))\n",
    "    cost = -(1/m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
    "    return cost\n",
    "\n",
    "# Gradient descent function definition\n",
    "def gradient_descent(X, y, W, alpha, epsilon, epochs):\n",
    "    m = y.shape[0]\n",
    "    cost_history = []  # Keep track of the cost every epoch for plotting/verification purposes\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Step 1: Calculate the hypothesis h using matrix multiplication\n",
    "        h = sigmoid(np.dot(X, W))\n",
    "        \n",
    "        # Step 2: Calculate the error\n",
    "        error = h - y\n",
    "        \n",
    "        # Step 3: Calculate the gradient using matrix multiplication\n",
    "        gradient = np.dot(X.T, error) / m\n",
    "        \n",
    "        # Step 4: Update the weights using matrix subtraction and scalar multiplication\n",
    "        W_old = W.copy()\n",
    "        W = W - alpha * gradient\n",
    "        \n",
    "        # Optional: Save the cost to the history for later\n",
    "        cost = compute_cost(X, y, W)\n",
    "        cost_history.append(cost)\n",
    "        \n",
    "        # Step 5: Check for convergence (if the change in cost function is less than epsilon)\n",
    "        if np.all(np.abs(W_old - W) < epsilon):\n",
    "            print(f'Convergence reached at epoch: {epoch}')\n",
    "            break\n",
    "    \n",
    "    return W, cost_history\n",
    "\n",
    "# Perform gradient descent\n",
    "W, cost_history = gradient_descent(X, y, W, alpha, epsilon, epochs)\n",
    "\n",
    "# Output the final weights and cost\n",
    "print(\"Final weights:\", W)\n",
    "print(\"Final cost:\", cost_history[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ffaeac-875f-42fd-a4af-d3d939dd8cd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming that 'W' are the weights after performing gradient descent,\n",
    "# 'X' is the feature matrix, and 'y' is the true labels\n",
    "\n",
    "# Calculate predictions\n",
    "h = sigmoid(np.dot(X, W))\n",
    "\n",
    "# Threshold the predictions to get binary class predictions\n",
    "y_pred = h >= 0.5\n",
    "\n",
    "# Plot of cost vs epochs\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cost_history)\n",
    "plt.title('Cost vs Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot of y_true vs y_pred\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y, h, alpha=0.5)\n",
    "plt.title('Scatter plot of actual vs. predicted')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0633238-d82c-4e91-a139-90ecb1af2ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
